{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision and Pattern Recognition - Project 3 (CNN classifier)\n",
    "#### Gaia Marsich [SM3500600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introduction](#intro)\n",
    "* [1. Task 1](#1-bullet)\n",
    "* [2. Task 2](#2-bullet)\n",
    "* [3. Task 3](#3-bullet)\n",
    "* [References](#ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a class=\"anchor\" id=\"#intro\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project requires the implementation of an image classifier based on convolutional neural networks. The provided dataset (from [Lazebnik et al., 2006]), contains 15 categories (office, kitchen, living room, bedroom, store, industrial, tall building, inside city, street, highway, coast, open country, mountain, forest, suburb), and is already divided in training set and test set.\n",
    "\n",
    "First of all, let's do the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torchvision\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from datetime import datetime\n",
    "# import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 <a class=\"anchor\" id=\"#1-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Build the network\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    # A model will have an __init__() function, where it instantiates its layers\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() # the constructor of the parent class (nn.Module) is called to initialize the model properly.\n",
    "\n",
    "        # Convolutional layer 1: in_channels=1 since the images are in greyscale\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1) # from [1] we get the formula: output = ((input - kernel_size + 2*padding)/stride) + 1 => 62*62\n",
    "        # ReLU activation after conv1\n",
    "        self.relu1 = nn.ReLU() # output: 62*62 #TODO OK\n",
    "        # Max pooling layer 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 31*31 (from 62/2)\n",
    "\n",
    "        # Convolutional layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1) # from [1] we know that output: 29*29\n",
    "        # ReLU activation after conv2\n",
    "        self.relu2 = nn.ReLU() # output: 29*29 #TODO OK\n",
    "        # Max pooling layer 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 14*14 (from the test in dim_images.ipynb)\n",
    "\n",
    "        # Convolutional layer 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1) # from [1] we know that output: 12*12\n",
    "        # ReLU activation after conv3  \n",
    "        self.relu3 = nn.ReLU() # output: 12*12\n",
    "\n",
    "        # Fully connected layer. 32: number of channels; 12, 12: height and width of the feature map\n",
    "        self.fc = nn.Linear(32 * 12 * 12, 15) #TODO OK\n",
    "        # Classification layer\n",
    "        #self.output = nn.CrossEntropyLoss() #TODO: ma è giusto da mettere? Al momento è tolto\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def initialize_weights(self):       #TODO: write comments here\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "                init.normal_(module.weight, mean=0, std=0.01)\n",
    "                if module.bias is not None:\n",
    "                    init.constant_(module.bias, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # A model will have a forward() function\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = x.view(-1, 32 * 12 * 12)  # flatten the tensor before passing to fully connected layers (the size -1 is inferred from other dimensions)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        #x = self.output(x) #TODO: in caso, da eliminare\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the provided training set in 85% for actual training set and 15% to be used as validation set\n",
    "\n",
    "resized_train_path = '/Users/Gaia/Desktop/CVPR-project/CVPR-project/resized/train'\n",
    "\n",
    "dataset_train = ImageFolder(root=resized_train_path, transform=transforms.ToTensor())\n",
    "\n",
    "train_size = int(0.85 * len(dataset_train))\n",
    "val_size = len(dataset_train) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset_train, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) # batch_size=32 required by the project\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True) # batch_size=32 required by the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = CNN()\n",
    "\n",
    "\n",
    "# Training\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), momentum=0.9) # the momentum by default is 0, but I need it different from 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch_index, loader): # to train for just one epoch (one epoch: the network sees the whole training set)\n",
    "    running_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "\n",
    "        inputs, labels = data # get the minibatch\n",
    "\n",
    "        outputs = model(inputs) # forward pass\n",
    "\n",
    "        loss = loss_function(outputs, labels) # compute the loss\n",
    "        running_loss += loss.item() # sum up the loss for the minibatches processed so far\n",
    "\n",
    "        optimizer.zero_grad() # notice that by default, the gradients are accumulated, hence we need to set them to zero\n",
    "        loss.backward() # backward pass\n",
    "        optimizer.step() # update the weights\n",
    "\n",
    "    return running_loss/(i+1) # average loss per minibatch\n",
    "\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 5\n",
    "\n",
    "print('Training loop...')\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(epoch,cifar2_train_loader)\n",
    "    print(f'Epoch [{epoch + 1}/{EPOCHS}], Loss: {train_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 <a class=\"anchor\" id=\"#2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 <a class=\"anchor\" id=\"#3-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a class=\"anchor\" id=\"ref\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://dingyan89.medium.com/calculating-parameters-of-convolutional-and-fully-connected-layers-with-keras-186590df36c6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
