{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision and Pattern Recognition - Project 3 (CNN classifier)\n",
    "#### Gaia Marsich [SM3500600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introduction](#intro)\n",
    "* [1. Task 1](#1-bullet)\n",
    "* [2. Task 2](#2-bullet)\n",
    "* [3. Task 3](#3-bullet)\n",
    "* [References](#ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a class=\"anchor\" id=\"#intro\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project requires the implementation of an image classifier based on convolutional neural networks. The provided dataset (from [Lazebnik et al., 2006]), contains 15 categories (office, kitchen, living room, bedroom, store, industrial, tall building, inside city, street, highway, coast, open country, mountain, forest, suburb), and is already divided in training set and test set.\n",
    "\n",
    "First of all, let's do the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from datetime import datetime\n",
    "# import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 <a class=\"anchor\" id=\"#1-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# build the network\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    # A model will have an __init__() function, where it instantiates its layers\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() # the constructor of the parent class (nn.Module) is called to initialize the model properly.\n",
    "\n",
    "        # Convolutional layer 1: in_channels=1 since the images are in greyscale\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1) # from [1] we get the formula: output = ((input - kernel_size + 2*padding)/stride) + 1 => 62*62\n",
    "        # ReLU activation after conv1\n",
    "        self.relu1 = nn.ReLU() # output: 62*62 #TODO\n",
    "        # Max pooling layer 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 31*31 (from 62/2)\n",
    "\n",
    "        # Convolutional layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1) # from [1] we know that output: 29*29\n",
    "        # ReLU activation after conv2\n",
    "        self.relu2 = nn.ReLU() # output: 29*29 #TODO\n",
    "        # Max pooling layer 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 14*14 (from floor(29/2), since MaxPool does this approximation) #TODO\n",
    "\n",
    "        # Convolutional layer 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1) # from [1] we know that output: 12*12\n",
    "        # ReLU activation after conv3  \n",
    "        self.relu3 = nn.ReLU() # output: 12*12\n",
    "\n",
    "        # Fully connected layer. 32: number of channels; 12, 12: height and width of the feature map\n",
    "        self.fc = nn.Linear(32 * 12 * 12, 15) #TODO\n",
    "        # Classification layer\n",
    "        self.output = nn.CrossEntropyLoss()  \n",
    "\n",
    "\n",
    "    # A model will have a forward() function\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = x.view(-1, 32 * 12 * 12)  # flatten the tensor before passing to fully connected layers (the size -1 is inferred from other dimensions)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 <a class=\"anchor\" id=\"#2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 <a class=\"anchor\" id=\"#3-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a class=\"anchor\" id=\"ref\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://dingyan89.medium.com/calculating-parameters-of-convolutional-and-fully-connected-layers-with-keras-186590df36c6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
