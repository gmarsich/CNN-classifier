{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, EPOCHS, train_loader, val_loader, optimizer, loss_function):\n",
    "\n",
    "    best_validation_loss = np.inf\n",
    "\n",
    "    loss_train = []  # store the values of the loss for the training set\n",
    "    loss_val = []    # store the values of the loss for the validation set\n",
    "    accuracies_train = []  # store the values of the accuracy for the training set\n",
    "    accuracies_val = []    # store the values of the accuracy for the validation set\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, loss_function)\n",
    "        loss_train.append(train_loss)\n",
    "\n",
    "        running_validation_loss = 0.0\n",
    "\n",
    "        # If using dropout and/or batch normalization, set the model to evaluation mode for validation\n",
    "        model.eval()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # disable gradient computation and reduce memory consumption\n",
    "            for i, vdata in enumerate(val_loader):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_function(voutputs, vlabels)\n",
    "                running_validation_loss += vloss\n",
    "                _, predicted = torch.max(voutputs.data, 1)\n",
    "                total += vlabels.size(0)\n",
    "                correct += (predicted == vlabels).sum().item()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "            accuracies_val.append(accuracy)\n",
    "\n",
    "        validation_loss = running_validation_loss / (i + 1)  # average validation loss per minibatch\n",
    "        loss_val.append(validation_loss)\n",
    "\n",
    "        print('LOSS: train: {}, validation: {}; accuracy validation set: {}%\\n'.format(train_loss, validation_loss,\n",
    "                                                                                        accuracy))\n",
    "\n",
    "        # Track best performance (based on validation), and save the model\n",
    "        if validation_loss < best_validation_loss:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            best_validation_loss = validation_loss\n",
    "            model_path = 'model_{}_{}'.format(timestamp, epoch)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        # Evaluate on the training set to calculate accuracy\n",
    "        model.eval()\n",
    "\n",
    "        running_train_correct = 0\n",
    "        running_train_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, tdata in enumerate(train_loader):\n",
    "                tinputs, tlabels = tdata\n",
    "                toutputs = model(tinputs)\n",
    "                _, predicted = torch.max(toutputs.data, 1)\n",
    "                running_train_total += tlabels.size(0)\n",
    "                running_train_correct += (predicted == tlabels).sum().item()\n",
    "\n",
    "            train_accuracy = 100 * running_train_correct / running_train_total\n",
    "            accuracies_train.append(train_accuracy)\n",
    "\n",
    "    return model_path, loss_train, loss_val, accuracies_train, accuracies_val\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
